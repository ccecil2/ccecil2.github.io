{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier for bord game reviews\n",
    "## By Chesley Cecil\n",
    "\n",
    "The implementation of the naive bayes algorithm is done entirely using functions from sklearn.naive_bayes\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "but the overall program had to be adapted to work with text data instead of the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chesley Cecil\n",
    "#12/10/2020\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "#Changes:\n",
    "#Changed test_size to 0.2\n",
    "#Changed input to be TF-IDF vectorized to allow for text input\n",
    "#Added a multi-nomial naive bayes classifier\n",
    "#Changed output to be accuracy instead of incorrect count\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "The data itself is from https://www.kaggle.com/jvanelteren/boardgamegeek-reviews?select=bgg-15m-reviews.csv and required a lot of pre-processing to be usable. I was able to host it on my GitHub in several parts because it was too big to store as a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  rating                                            comment\n",
      "0           0    10.0  I tend to either love or easily tire of co-op ...\n",
      "1           1    10.0  This is an amazing co-op game.  I play mostly ...\n",
      "2           2    10.0  Hey! I can finally rate this game I've been pl...\n",
      "3           3    10.0  Love it- great fun with my son. 2 plays so far...\n",
      "4           4    10.0  Fun, fun game. Strategy is required, but defin...\n",
      "   Unnamed: 0  rating                                            comment\n",
      "0      125000     6.5                          My first step into gaming\n",
      "1      125001     6.5  Still has a certain charm. Lolts of better stu...\n",
      "2      125002     6.5  I like to say that my first wargame was Guadal...\n",
      "3      125003     6.5                             classic but too simple\n",
      "4      125004     6.5  This was a game we played relentlessly until w...\n",
      "   Unnamed: 0  rating                                            comment\n",
      "0      252218     7.0  A decent deck-builder that has you move around...\n",
      "1      252219     7.0  Fun, quick deck builder with a fresh clever pu...\n",
      "2      252220     7.0  One play deep and I am impressed.  I am not su...\n",
      "3      252221     7.0  I really enjoyed my first play of this game. A...\n",
      "4      252222     7.0                                  All Cards Sleeved\n",
      "   Unnamed: 0  rating                                            comment\n",
      "0      375498     7.0  :d6-1: Ok as solitaire Nice puzzle game that I...\n",
      "1      375499     7.0  Quick game but I am personally terrible at thi...\n",
      "2      375500     7.0  Simple to teach. Not a game that has me trying...\n",
      "3      380022     6.0  My girlfriend and I agree -  too simple, too l...\n",
      "4      380023     6.0   A bit dry but quick and easy 2 player card game.\n",
      "   Unnamed: 0  rating                                            comment\n",
      "0      500000     6.0  There doesn't appear to be that much strategy ...\n",
      "1      500001     6.0  [b]Pandemic[/b] was sold via auction (2013).  ...\n",
      "2      500002     6.0  Very good game, but almost fired by some of it...\n",
      "3      500003     6.0  Very challenging co-op game; the group prefers...\n",
      "4      500004     6.0  RICHARD OWNS THIS ONE  I can see why this game...\n"
     ]
    }
   ],
   "source": [
    "#Load data parts\n",
    "\n",
    "part_0 = pd.read_csv(\"https://raw.githubusercontent.com/ccecil2/ccecil2.github.io/master/downloads/new_reviews_part_0.csv\", error_bad_lines=False)\n",
    "\n",
    "part_1 = pd.read_csv(\"https://raw.githubusercontent.com/ccecil2/ccecil2.github.io/master/downloads/new_reviews_part_1.csv\", error_bad_lines=False)\n",
    "\n",
    "part_2 = pd.read_csv(\"https://raw.githubusercontent.com/ccecil2/ccecil2.github.io/master/downloads/new_reviews_part_2.csv\", error_bad_lines=False)\n",
    "\n",
    "part_3 = pd.read_csv(\"https://raw.githubusercontent.com/ccecil2/ccecil2.github.io/master/downloads/new_reviews_part_3.csv\", error_bad_lines=False)\n",
    "\n",
    "part_4 = pd.read_csv(\"https://raw.githubusercontent.com/ccecil2/ccecil2.github.io/master/downloads/new_reviews_part_4.csv\", error_bad_lines=False)\n",
    "\n",
    "print(part_0[0:5])\n",
    "\n",
    "print(part_1[0:5])\n",
    "\n",
    "print(part_2[0:5])\n",
    "\n",
    "print(part_3[0:5])\n",
    "\n",
    "print(part_4[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the data\n",
    "Because the data was stored and loaded in parts, it has to be merged into a single dataframe for use later in the program. Additionally, the ratings (a value on a scale from 0 to 10) were rounded to make the data simplier as there were numerous issues with the values not being reasonable (one was 9.01799999999999, and there were others that were just as bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  rating                                            comment\n",
      "0           0      10  I tend to either love or easily tire of co-op ...\n",
      "1           1      10  This is an amazing co-op game.  I play mostly ...\n",
      "2           2      10  Hey! I can finally rate this game I've been pl...\n",
      "3           3      10  Love it- great fun with my son. 2 plays so far...\n",
      "4           4      10  Fun, fun game. Strategy is required, but defin...\n"
     ]
    }
   ],
   "source": [
    "#Merge data parts\n",
    "\n",
    "data = part_0\n",
    "\n",
    "data = data.append(part_1, ignore_index=True)\n",
    "\n",
    "data = data.append(part_2, ignore_index=True)\n",
    "\n",
    "data = data.append(part_3, ignore_index=True)\n",
    "\n",
    "data = data.append(part_4, ignore_index=True)\n",
    "\n",
    "#Rounds the ratings to make it easier to train the models\n",
    "data[\"rating\"] = data[\"rating\"].map(lambda x: round(x))\n",
    "\n",
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the data from the DataFrames\n",
    "When a column is extracted from a DataFrame, it is turned into a Series, somehting that can't be used by Sklearn. To avoid that issue, the resulting Series were turned into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I tend to either love or easily tire of co-op games.  Pandemic joins Knizia's LoTR as my favorite true co-op.  It edges LoTR out merely in time to set-up and play.  LoTR can be an undertaking to explain enough details so that players enjoy their first time through the game, while Pandemic is fast enough that even if the players don't quite get everything that is going on, they can try again immediately.\", \"This is an amazing co-op game.  I play mostly with my wife and this is a game that I can't really imagine getting tired of.  Win or lose, I usually want to play again immediately.  On the Brink and the fan-made expansion from on ArtsCow add much more variety and good game play, only enhancing an already great game.\", 'Hey! I can finally rate this game I\\'ve been playtesting on and off for a couple years. I really like Pandemic, it\\'s the best cooperative game I\\'ve played since Lord of the Rings. The key is in the pacing; the game successfully ratchets up the tension as infections spread and outbreaks pop up all over the place, and the players fight a race against time to conquer the various diseases. The game is just a perfect length, about 45 minutes, and the endgame tension is just right - the game doesn\\'t end before it\\'s over. The different roles give the players significantly different prisms through which to look at the game, which is helpful in cleanly driving table-talk and discussion without phony artificial restrictions like Shadows over Camelot had. All in all, this is finally another good cooperative game that gamers can enjoy. It\\'s not as deep as Lord of the Rings, but it\\'s also simpler and shorter and should be accessible to a wide variety of players.  Gamers should probably bypass the \"easy\" game and go straight to the standard game.  If you\\'d like to tweak the difficulty a little bit without going straight to Heroic level (which can be pretty tough) try starting the infection rate marker on the second or third space.', 'Love it- great fun with my son. 2 plays so far and looking forward to more!', \"Fun, fun game. Strategy is required, but definitely accessible to non-gamers. Have played it 2 player with my 5 1/2 year old son (using 4 roles and open hands), and he thinks it is his favorite game now. Played it 3 player with my son and my 8 year old daughter, and it was great too. Also very much enjoyed a solitaire game playing 3 roles. This will definitely be one of the most played games for the next few months. I originally rated this a 9.5, but I can't figure out why I took off half a point.\"]\n",
      "[10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "#Turns the data into lists\n",
    "X = data[\"comment\"].to_list()\n",
    "\n",
    "y = data[\"rating\"].to_list()\n",
    "\n",
    "print(X[0:5])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data\n",
    "After the entirety of the data has been extracted, it has to be broken into test and train parts. In this case, the ratio of train to test data is 8:2 since Naive Bayes works better the more training data it has. Additionally, there are two versions of the split data in order to test the two different pre-processing methods used in the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base\n",
    "\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sub\n",
    "\n",
    "X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the data\n",
    "Now that the data has been split into train and test parts, it has to be pre-processed into TF-IDF matrices to allow it to be used with the Sklearn Naive Bayes functions. The \"base\" vectorizer has sublinear_tf as False while the \"sub\" vectorizer has it as True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_base = TfidfVectorizer(min_df=0.001)\n",
    "\n",
    "train_base = vectorizer_base.fit_transform(X_train_base)\n",
    "test_base = vectorizer_base.transform(X_test_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_sublinear = TfidfVectorizer(min_df=0.001, sublinear_tf=True)\n",
    "\n",
    "train_sub = vectorizer_sublinear.fit_transform(X_train_sub)\n",
    "test_sub = vectorizer_sublinear.transform(X_test_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further pre-procesing\n",
    "The vectorizers produce the TF-IDF matrix in the form of a sparse matrix, which can't be used by Sklearn, so the todense method is used to turn it into a regular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_dense = train_base.todense()\n",
    "test_base_dense = test_base.todense()\n",
    "\n",
    "train_sub_dense = train_sub.todense()\n",
    "test_sub_dense = test_sub.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model types\n",
    "The two types of Naive Bayes models that are being examined are Gaussian and Multinomial. According to the Sklearn documentation, Multinomial Naive Bayes is used for text classification, so it is presumed to work better than Gaussian Naive Bayes for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = GaussianNB()\n",
    "multi = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "With everything set up, the models can be tested on the data to determine their accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.116057\n"
     ]
    }
   ],
   "source": [
    "#Base gauss\n",
    "\n",
    "y_pred_base_gauss = gauss.fit(train_base_dense, y_train_base).predict(test_base_dense)\n",
    "\n",
    "base_gauss_acc = ((y_test_base == y_pred_base_gauss).sum() / test_base_dense.shape[0])\n",
    "\n",
    "print(\"Accuracy: %f\" % (base_gauss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.115650\n"
     ]
    }
   ],
   "source": [
    "#Sub gauss\n",
    "\n",
    "y_pred_sub_gauss = gauss.fit(train_sub_dense, y_train_sub).predict(test_sub_dense)\n",
    "\n",
    "sub_gauss_acc = ((y_test_sub == y_pred_sub_gauss).sum() / test_sub_dense.shape[0])\n",
    "\n",
    "print(\"Accuracy: %f\" % (sub_gauss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.352770\n"
     ]
    }
   ],
   "source": [
    "#Base multi\n",
    "\n",
    "y_pred_base_multi = multi.fit(train_base_dense, y_train_base).predict(test_base_dense)\n",
    "\n",
    "base_multi_acc = ((y_test_base == y_pred_base_multi).sum() / test_base_dense.shape[0])\n",
    "\n",
    "print(\"Accuracy: %f\" % (base_multi_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.352941\n"
     ]
    }
   ],
   "source": [
    "#Sub multi\n",
    "\n",
    "y_pred_sub_multi = multi.fit(train_sub_dense, y_train_sub).predict(test_sub_dense)\n",
    "\n",
    "sub_multi_acc = ((y_test_sub == y_pred_sub_multi).sum() / test_sub_dense.shape[0])\n",
    "\n",
    "print(\"Accuracy: %f\" % (sub_multi_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of loading the model later, the best model (multinomial sublinear in my testing) and its corresponding vectorizer are saved into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump(multi, 'naive_bayes.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump(vectorizer_sublinear, 'vectorize.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Now that all of the models have run, their accuracies can be evaluated to determine which was the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best option was the Multinomial Naive Bayes with sublinear term frequencies\n"
     ]
    }
   ],
   "source": [
    "#Determine which is best\n",
    "\n",
    "accuracies = np.array([base_gauss_acc, sub_gauss_acc, base_multi_acc, sub_multi_acc])\n",
    "\n",
    "max_index = np.argmax(accuracies)\n",
    "\n",
    "if max_index == 0:\n",
    "    print(\"The best option was the Gaussian Naive Bayes without sublinear term frequencies\")\n",
    "elif max_index == 1:\n",
    "    print(\"The best option was the Gaussian Naive Bayes with sublinear term frequencies\")\n",
    "elif max_index == 2:\n",
    "    print(\"The best option was the Multinomial Naive Bayes without sublinear term frequencies\")\n",
    "else:\n",
    "    print(\"The best option was the Multinomial Naive Bayes with sublinear term frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
